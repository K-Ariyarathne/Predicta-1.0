{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "UDpVbjzfjACi",
        "outputId": "2f184409-fe55-4970-bd6c-0ccf8f5f5cb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.0.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-73427d45-a55b-4ea5-a07c-da9a4c966bf2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-73427d45-a55b-4ea5-a07c-da9a4c966bf2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install necessary libraries\n",
        "!pip install kaggle seaborn scikit-learn\n",
        "\n",
        "# Step 2: Upload kaggle.json\n",
        "from google.colab import files\n",
        "files.upload()  # This will prompt you to upload the kaggle.json file\n",
        "\n",
        "# Step 3: Move kaggle.json to the appropriate directory\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sDtChk5jRT8",
        "outputId": "4486cf49-5de2-44cb-8e52-f4b89f75079a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading predicta-1-0-predict-the-unpredictable.zip to /content\n",
            "\r  0% 0.00/1.94M [00:00<?, ?B/s]\n",
            "\r100% 1.94M/1.94M [00:00<00:00, 121MB/s]\n",
            "Archive:  predicta-1-0-predict-the-unpredictable.zip\n",
            "  inflating: historical_weather.csv  \n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: submission_key.csv      \n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c predicta-1-0-predict-the-unpredictable\n",
        "!unzip predicta-1-0-predict-the-unpredictable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh-ZnN1SHnuU",
        "outputId": "622f2888-15a6-46f3-8a33-eac8e9d440db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 300, 'subsample': 1.0}\n",
            "Best RMSE: 2.5937769685005505\n",
            "RMSE on 2018 test set after hyperparameter tuning: 2.450861876691023\n",
            "     city_id       date  year  month  day  dayofweek  dayofyear  \\\n",
            "0          0 2019-01-01  2019      1    1          1          1   \n",
            "1          0 2019-01-02  2019      1    2          2          2   \n",
            "2          0 2019-01-03  2019      1    3          3          3   \n",
            "3          0 2019-01-04  2019      1    4          4          4   \n",
            "4          0 2019-01-05  2019      1    5          5          5   \n",
            "..       ...        ...   ...    ...  ...        ...        ...   \n",
            "695       99 2019-01-03  2019      1    3          3          3   \n",
            "696       99 2019-01-04  2019      1    4          4          4   \n",
            "697       99 2019-01-05  2019      1    5          5          5   \n",
            "698       99 2019-01-06  2019      1    6          6          6   \n",
            "699       99 2019-01-07  2019      1    7          0          7   \n",
            "\n",
            "     predicted_avg_temp_c  \n",
            "0                8.073177  \n",
            "1                7.513272  \n",
            "2                7.502435  \n",
            "3                7.769464  \n",
            "4                7.778315  \n",
            "..                    ...  \n",
            "695             21.144079  \n",
            "696             20.792645  \n",
            "697             20.798271  \n",
            "698             20.276926  \n",
            "699             20.485474  \n",
            "\n",
            "[700 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('historical_weather.csv')\n",
        "\n",
        "# Convert date to datetime and extract features\n",
        "data['date'] = pd.to_datetime(data['date'])\n",
        "data['year'] = data['date'].dt.year\n",
        "data['month'] = data['date'].dt.month\n",
        "data['day'] = data['date'].dt.day\n",
        "data['dayofweek'] = data['date'].dt.dayofweek  # New feature: Day of week\n",
        "data['dayofyear'] = data['date'].dt.dayofyear  # New feature: Day of year\n",
        "\n",
        "# Impute missing avg_temp_c with mean of avg_temp_c for each city\n",
        "data['avg_temp_c'] = data.groupby('city_id')['avg_temp_c'].transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        "# Encode city_id as a categorical feature\n",
        "data['city_id'] = data['city_id'].astype('category').cat.codes\n",
        "\n",
        "# Define features and target\n",
        "features = ['city_id', 'year', 'month', 'day', 'dayofweek', 'dayofyear']\n",
        "target = 'avg_temp_c'\n",
        "\n",
        "# Split the data into features and target\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Scale the features\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Initialize the model\n",
        "model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)  # Use squarederror for regression\n",
        "\n",
        "# Set up KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],  # Number of boosting rounds\n",
        "    'learning_rate': [0.05, 0.1, 0.2],  # Step size shrinkage to prevent overfitting\n",
        "    'max_depth': [3, 4, 5],  # Maximum depth of a tree\n",
        "    'min_child_weight': [1, 3, 5],  # Minimum sum of instance weight (hessian) needed in a child\n",
        "    'subsample': [0.6, 0.8, 1.0],  # Subsample ratio of the training instances\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0]  # Subsample ratio of columns when constructing each tree\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=kf, scoring='neg_root_mean_squared_error')\n",
        "grid_search.fit(X_scaled, y)\n",
        "\n",
        "# Print the best parameters and RMSE\n",
        "print(f'Best parameters: {grid_search.best_params_}')\n",
        "print(f'Best RMSE: {-grid_search.best_score_}')\n",
        "\n",
        "# Train the model on the full training data with the best parameters\n",
        "best_model = grid_search.best_estimator_\n",
        "best_model.fit(X_scaled, y)\n",
        "\n",
        "# Predict and evaluate on the test set (for 2018 data)\n",
        "test_data = data[data['year'] == 2018]\n",
        "X_test = scaler.transform(test_data[features])  # Scale test data\n",
        "y_test = test_data[target]\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "print(f'RMSE on 2018 test set after hyperparameter tuning: {rmse}')\n",
        "\n",
        "# Make predictions for 2019/01/01 to 2019/01/07\n",
        "future_dates = pd.date_range(start='2019-01-01', end='2019-01-07')\n",
        "future_data = pd.DataFrame({\n",
        "    'city_id': np.repeat(range(100), len(future_dates)),\n",
        "    'date': future_dates.tolist() * 100\n",
        "})\n",
        "future_data['year'] = future_data['date'].dt.year\n",
        "future_data['month'] = future_data['date'].dt.month\n",
        "future_data['day'] = future_data['date'].dt.day\n",
        "future_data['dayofweek'] = future_data['date'].dt.dayofweek  # New feature: Day of week\n",
        "future_data['dayofyear'] = future_data['date'].dt.dayofyear  # New feature: Day of year\n",
        "future_data['city_id'] = future_data['city_id'].astype('category').cat.codes\n",
        "\n",
        "X_future = scaler.transform(future_data[features])  # Scale future data\n",
        "future_data['predicted_avg_temp_c'] = best_model.predict(X_future)\n",
        "\n",
        "predicted_temperatures = future_data['predicted_avg_temp_c'].values\n",
        "print(future_data)\n",
        "\n",
        "# Optionally, save to CSV\n",
        "future_data.to_csv('future_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-FvflWVatkr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Update the sample_submission.csv with predictions\n",
        "submission = pd.read_csv('sample_submission.csv')\n",
        "submission['predicted_avg_temp_c'] = predicted_temperatures\n",
        "submission.to_csv('sample_submission.csv', index=False)\n",
        "submission.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP-hBjgqbaWZ",
        "outputId": "c2dbe21b-a069-41cf-fa6a-6c7488337ae1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "submission_ID           0\n",
              "avg_temp_c              0\n",
              "predicted_avg_temp_c    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbcGFBTSbbFm",
        "outputId": "fcfa53c3-6f45-4308-dda8-4403447d1baf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     submission_ID  avg_temp_c\n",
            "0                1    8.073177\n",
            "1                2    7.513272\n",
            "2                3    7.502435\n",
            "3                4    7.769464\n",
            "4                5    7.778315\n",
            "..             ...         ...\n",
            "695            696   21.144079\n",
            "696            697   20.792645\n",
            "697            698   20.798271\n",
            "698            699   20.276926\n",
            "699            700   20.485474\n",
            "\n",
            "[700 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Drop the 'avg_temp_c' column\n",
        "submission = submission.drop(columns=['avg_temp_c'])\n",
        "\n",
        "# Rename the 'predicted_avg_temp_c' column to 'avg_temp_c'\n",
        "submission = submission.rename(columns={'predicted_avg_temp_c': 'avg_temp_c'})\n",
        "\n",
        "print(submission)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(submission)"
      ],
      "metadata": {
        "id": "nDnyDCAIAVZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the updated DataFrame to sample_submission.csv\n",
        "submission.to_csv('sample_submission.csv', index=False)\n",
        "\n",
        "# Download the file\n",
        "from google.colab import files\n",
        "files.download('sample_submission.csv')"
      ],
      "metadata": {
        "id": "ESOYDNTBxR36"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}